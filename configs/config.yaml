
initializations: 
  - random
  - pessimistic
  - optimistic

f_initializations: 
  - ones
  - random 
  #- 0_to_20
  - greater_than_one
  - zeros
  - twenty

random_initialization_seed: null

#f_table_init: 'random'

num_runs: 5

offset: 0.001

env: 
  height: 20
  width: 11
  rewards: [[1,10,5]] #[[1, 10, 5]] #[[1,0,5]] #[[1,10,5]] #[[1, 1, 6], [1, 3, 4]]
  wind: no
  start: random
  allowed_actions: ['L', 'R', 'U', 'D', 'UL', 'UR', 'DL', 'DR'] #'C'
  reward_terminates_episode: yes

baseline: 
  discount: 0.98
  alpha: 0.01
  num_steps: 100000
  epsilon: 0.05

  show_rewards: yes
  show_q: yes
  show_trajectory: no

freetime:
  num_steps: 100000
  epsilon: 0.05
  discount: 0.98
  alpha: 0.01
  alpha_f: 0.1
  tolerance: 0

  show_rewards: yes
  show_q: yes
  show_f: yes
  show_f_actions:
    - min
    #- 0
  show_trajectory: no

trajectory_maps:
  num_plots: 2

q_plots:
  vmin: 0
  vmax: 1

f_plots: 
  vmin: null
  vmax: null

plot_freetime_vs_baseline_same_table: True