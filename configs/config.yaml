
initializations: 
  #- random
  - pessimistic
  - optimistic

f_initializations: 
   - ones
  #- random 
  #- 0_to_20
  #- greater_than_one
  #- zeros
 # - twenty

random_initialization_seed: null

#f_table_init: 'random'

num_runs: 1

offset: 0.001

env: 
  height: 20
  width: 1
  rewards: [[1,0,0],[2,0,10]] #[[2, 1, 6], [1, 3, 4],[1, 14, 4]] #[[1, 10, 5]] #[[1,0,5]] #[[1,10,5]] #[[1, 1, 6], [1, 3, 4]]
  wind: no
  start: random
  allowed_actions: ['L', 'R', 'U', 'D'] #'UL', 'UR', 'DL', 'DR'] #'C'
  reward_terminates_episode: no

baseline: 
  discount: 0.98
  alpha: 0.01
  num_steps: 300000
  epsilon: 0.05

  show_rewards: yes
  show_q: yes
  show_trajectory: no

freetime:
  num_steps: 0
  epsilon: 0.05
  discount: 0.98
  alpha: 0.01
  alpha_f: 0.1
  tolerance: 0

  show_rewards: yes
  show_q: yes
  show_f: yes
  show_f_actions:
    - min
    #- 0
  show_trajectory: no

trajectory_maps:
  num_plots: 2

q_plots:
  vmin: 0.9
  vmax: 1

f_plots: 
  vmin: null
  vmax: null

plot_freetime_vs_baseline_same_table: True